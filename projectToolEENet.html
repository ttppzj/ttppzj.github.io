<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>ToolEENet</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>ToolEENet</b>: Tool Affordance 6D Pose Estimation</br> 
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://github.com/yl-wang996/">
                          Yunlong Wang
                        </a>
                    </li>
                    <li>
                        <a href="http://leizhang-public.github.io/">
                            Lei Zhang
                        </a>
                    </li>
                    <li>
                        <a href="https://tams.informatik.uni-hamburg.de/people/tu/">
                          Yuyang Tu*
                        </a>
                    </li>
                    <li>
                        <a href="https://tams.informatik.uni-hamburg.de/people/zhangh/">
                          Hui Zhang
                        </a>
                    </li>
                    <li>
                        <a href="https://baikaixin-public.github.io/">
                          Kaixin Bai
                        </a>
                    </li>
		     <li>
                        <a href="https://ieeexplore.ieee.org/author/37404312400">
                          Zhaopeng Chen
                        </a>
                    </li>
		     <li>
                        <a href="https://tams.informatik.uni-hamburg.de/people/zhang/">
                          Jianwei Zhang
                        </a>
                    </li>
                </ul>
            </div>
        </div>
	<div class="row">
    	    <div class="col-md-12 text-center">
               <p><a href="https://tams.informatik.uni-hamburg.de/">Technical Aspects of Multimodal Systems (TAMS), University of Hamburg</a></p>
            </div>
        </div>


        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2404.04193">
                            <image src="ToolEENet/img/zip_paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://youtu.be/B-a8YhIv3kc">
                            <image src="ToolEENet/img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/yl-wang996/ToolEENet">
                            <image src="ToolEENet/img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
		        <li>
                            <a href="https://drive.google.com/drive/u/0/folders/1GTUYQKX9m7vCOi_mMaqV0_3qmlNusxUT">
                            <image src="ToolEENet/img/drive.png" height="60px">
                                <h4><strong>Dataset</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
    	    <div class="col-md-8 col-md-offset-2">
        
                <img id="image-display" src="ToolEENet/img/paperabstract.PNG" style="width: 100%; height: auto;">
    	    </div>
	</div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
The exploration of robotic dexterous hands utilizing tools has recently attracted considerable attention. A significant challenge in this field is the precise awareness of a tool’s pose when grasped, as occlusion by the hand often degrades the quality of the estimation. Additionally, the tool’s overall pose often fails to accurately represent the contact interaction, thereby limiting the effectiveness of vision-guided, contact-dependent activities. To overcome this limitation, we present the innovative TOOLEE dataset, which, to the best of our knowledge, is the first to feature affordance segmentation of a tool’s end-effector (EE) along with its defined 6D pose based on its usage. Furthermore, we propose the ToolEENet framework for accurate 6D pose estimation of the tool’s EE. This framework begins by segmenting the tool’s EE from raw RGBD data, then uses a diffusion model-based pose estimator for 6D pose estimation at a category-specific level. Addressing the issue of symmetry in pose estimation, we introduce a symmetry-aware pose representation that enhances the consistency of pose estimation. Our approach excels in this field, demonstrating high levels of precision and generalization. Furthermore, it shows great promise for application in contact-based manipulation scenarios. 
                </p>
            </div>
        </div>

	<div class="row">
            <div class="col-md-8 col-md-offset-2">
		<h3>
                    Video
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="ToolEENet/img/experiment.mp4" type="video/mp4" />
                </video>
						</div>
        </div>

           

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
